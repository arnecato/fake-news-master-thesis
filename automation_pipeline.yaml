document_embedding:
  models:
      - "python ./bert.py --model_name=bert-base-cased"
      - "python ./bert.py --model_name=distilbert-base-cased"
      - "python ./bert.py --model_name=roberta-base"
      - "python ./fast_text.py"

umap_dimensionality_reduction:
  dims:
    - 1
    - 2
    #- 3
    #- 4
  embeddings:
    - bert-base-cased
    - distilbert-base-cased
    - roberta-base
    - fasttext
  tool: "python ./umap_tool.py umap --filepath_true=dataset/ISOT/True_{embedding}.h5 --filepath_fake=dataset/ISOT/Fake_{embedding}.h5 --word_embedding={embedding} --dim={dim} --neighbors=15 --umap_sample_size=25700 --sample_size=21417 --min_dist=0.0 --postfix=true_only"

model_training:
  - name: "nsgaii_nsa"
    tool: "python ./nsgaii_nsa.py"
    sample_size: -1
    max_amount: 3000
    convergence_every: 25
    coverage: 0.0005 # required increase in negative space coverage
    dims:
      - 1
      - 2
      - 3
      - 4 
    embeddings:
      - fasttext
      - distilbert-base-cased
      - bert-base-cased
      - roberta-base
    self_region:
      1: -1
      2: -1 #0.03
      3: -1 #0.01
      4: -1 #0.005
    dataset_path: "dataset/ISOT/True_Fake_{embedding}_umap_{dim}dim_15_25700_21417.h5"
    output_path: "model/detector/detectors_{embedding}_{dim}dim_15_25700_21417_nsgaii_auto.json"
  - name: "ga_nsa"
    tool: "python ./ga_nsa.py"
    sample_size: -1
    max_amount: 3000
    convergence_every: 25
    coverage: 0.0005 # required increase in negative space coverage
    dims:
      - 1
      - 2
      - 3
      - 4 
    embeddings:
      - fasttext
      - distilbert-base-cased
      - bert-base-cased
      - roberta-base
    self_region:
      1: -1
      2: -1 #0.03
      3: -1 #0.01
      4: -1 #0.005
    dataset_path: "dataset/ISOT/True_Fake_{embedding}_umap_{dim}dim_15_25700_21417.h5"
    output_path: "model/detector/detectors_{embedding}_{dim}dim_15_25700_21417_auto.json"

  